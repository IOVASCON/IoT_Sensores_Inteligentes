{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning com MobileNetV2\n",
    "\n",
    "Neste notebook, implementamos o processo de Transfer Learning utilizando o modelo pré-treinado MobileNetV2. Vamos usar o modelo para classificar imagens de gatos e cães, aproveitando o conhecimento pré-existente do modelo sobre o conjunto de dados ImageNet.\n",
    "\n",
    "## Etapas do processo:\n",
    "1. Carregamento do dataset.\n",
    "2. Preparação dos datasets de treino e validação.\n",
    "3. Aumentação de dados para evitar overfitting.\n",
    "4. Criação do modelo base (MobileNetV2).\n",
    "5. Adição da camada de classificação personalizada.\n",
    "6. Treinamento e avaliação do modelo.\n",
    "7. Fine-tuning para melhorar a performance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "  \"cells\": [\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"# Transfer Learning com MobileNetV2\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"import matplotlib.pyplot as plt\\n\",\n",
    "        \"import numpy as np\\n\",\n",
    "        \"import os\\n\",\n",
    "        \"import tensorflow as tf\\n\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"## Download e extração do dataset\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\\n\",\n",
    "        \"path_to_zip = tf.keras.utils.get_file('cats_and_dogs.zip', origin=_URL, extract=True)\\n\",\n",
    "        \"PATH = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')\\n\",\n",
    "        \"\\n\",\n",
    "        \"train_dir = os.path.join(PATH, 'train')\\n\",\n",
    "        \"validation_dir = os.path.join(PATH, 'validation')\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"## Preparando os datasets de treino e validação\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"BATCH_SIZE = 32\\n\",\n",
    "        \"IMG_SIZE = (160, 160)\\n\",\n",
    "        \"\\n\",\n",
    "        \"train_dataset = tf.keras.utils.image_dataset_from_directory(train_dir,\\n\",\n",
    "        \"                                                            shuffle=True,\\n\",\n",
    "        \"                                                            batch_size=BATCH_SIZE,\\n\",\n",
    "        \"                                                            image_size=IMG_SIZE)\\n\",\n",
    "        \"\\n\",\n",
    "        \"validation_dataset = tf.keras.utils.image_dataset_from_directory(validation_dir,\\n\",\n",
    "        \"                                                                 shuffle=True,\\n\",\n",
    "        \"                                                                 batch_size=BATCH_SIZE,\\n\",\n",
    "        \"                                                                 image_size=IMG_SIZE)\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"## Aumentação de dados para evitar overfitting\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"data_augmentation = tf.keras.Sequential([\\n\",\n",
    "        \"    tf.keras.layers.RandomFlip('horizontal'),\\n\",\n",
    "        \"    tf.keras.layers.RandomRotation(0.2),\\n\",\n",
    "        \"])\\n\",\n",
    "        \"\\n\",\n",
    "        \"preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"## Criando o modelo base (MobileNetV2)\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"IMG_SHAPE = IMG_SIZE + (3,)\\n\",\n",
    "        \"base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\\n\",\n",
    "        \"                                               include_top=False,\\n\",\n",
    "        \"                                               weights='imagenet')\\n\",\n",
    "        \"\\n\",\n",
    "        \"base_model.trainable = False\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"## Adicionando a cabeça de classificação\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\\n\",\n",
    "        \"prediction_layer = tf.keras.layers.Dense(1, activation='sigmoid')\\n\",\n",
    "        \"\\n\",\n",
    "        \"inputs = tf.keras.Input(shape=(160, 160, 3))\\n\",\n",
    "        \"x = data_augmentation(inputs)\\n\",\n",
    "        \"x = preprocess_input(x)\\n\",\n",
    "        \"x = base_model(x, training=False)\\n\",\n",
    "        \"x = global_average_layer(x)\\n\",\n",
    "        \"x = tf.keras.layers.Dropout(0.2)(x)\\n\",\n",
    "        \"outputs = prediction_layer(x)\\n\",\n",
    "        \"model = tf.keras.Model(inputs, outputs)\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"## Compilando e treinando o modelo\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"base_learning_rate = 0.0001\\n\",\n",
    "        \"model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=base_learning_rate),\\n\",\n",
    "        \"              loss=tf.keras.losses.BinaryCrossentropy(),\\n\",\n",
    "        \"              metrics=['accuracy'])\\n\",\n",
    "        \"\\n\",\n",
    "        \"initial_epochs = 10\\n\",\n",
    "        \"\\n\",\n",
    "        \"history = model.fit(train_dataset,\\n\",\n",
    "        \"                    epochs=initial_epochs,\\n\",\n",
    "        \"                    validation_data=validation_dataset)\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"## Avaliando o desempenho do modelo\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"acc = history.history['accuracy']\\n\",\n",
    "        \"val_acc = history.history['val_accuracy']\\n\",\n",
    "        \"loss = history.history['loss']\\n\",\n",
    "        \"val_loss = history.history['val_loss']\\n\",\n",
    "        \"\\n\",\n",
    "        \"plt.figure(figsize=(8, 8))\\n\",\n",
    "        \"plt.subplot(2, 1, 1)\\n\",\n",
    "        \"plt.plot(acc, label='Training Accuracy')\\n\",\n",
    "        \"plt.plot(val_acc, label='Validation Accuracy')\\n\",\n",
    "        \"plt.legend(loc='lower right')\\n\",\n",
    "        \"plt.ylabel('Accuracy')\\n\",\n",
    "        \"plt.ylim([min(plt.ylim()),1])\\n\",\n",
    "        \"plt.title('Training and Validation Accuracy')\\n\",\n",
    "        \"\\n\",\n",
    "        \"plt.subplot(2, 1, 2)\\n\",\n",
    "        \"plt.plot(loss, label='Training Loss')\\n\",\n",
    "        \"plt.plot(val_loss, label='Validation Loss')\\n\",\n",
    "        \"plt.legend(loc='upper right')\\n\",\n",
    "        \"plt.ylabel('Cross Entropy')\\n\",\n",
    "        \"plt.ylim([0,1.0])\\n\",\n",
    "        \"plt.title('Training and Validation Loss')\\n\",\n",
    "        \"plt.xlabel('epoch')\\n\",\n",
    "        \"plt.show()\"\n",
    "      ]\n",
    "    }\n",
    "  ],\n",
    "  \"metadata\": {\n",
    "    \"kernelspec\": {\n",
    "      \"display_name\": \"Python 3\",\n",
    "      \"language\": \"python\",\n",
    "      \"name\": \"python3\"\n",
    "    },\n",
    "    \"language_info\": {\n",
    "      \"name\": \"python\"\n",
    "    }\n",
    "  },\n",
    "  \"nbformat\": 4,\n",
    "  \"nbformat_minor\": 4\n",
    "}\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
